# LabelForge

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![PyPI](https://img.shields.io/badge/PyPI-0.1.0-green.svg)](https://pypi.org/project/labelforge/)
[![Tests](https://img.shields.io/badge/tests-passing-green.svg)](tests/)
[![Documentation](https://img.shields.io/badge/docs-latest-brightgreen.svg)](docs/)
[![Contributions Welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)

**Open-source framework for programmatic weak supervision and data labeling**

LabelForge is a research-oriented Python library for creating labeled datasets using weak supervision techniques. Inspired by academic research in programmatic labeling (Snorkel, Wrench), this tool allows researchers and practitioners to encode domain knowledge as simple labeling functions and combine them using probabilistic models to generate training labels for machine learning.

## Table of Contents

- [Overview](#overview)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [API Reference](#api-reference)
- [Examples](#examples)
- [Research & Citations](#research--citations)
- [Contributing](#contributing)
- [Community](#community)
- [License](#license)

## Overview

Weak supervision addresses the bottleneck of manual data labeling by allowing users to write labeling functions (LFs) that programmatically assign labels based on heuristics, patterns, or external knowledge. LabelForge implements:

- **Labeling Functions**: Simple Python functions that express domain knowledge
- **Label Model**: Probabilistic model (EM algorithm) that learns LF accuracies and correlations
- **End-to-End Pipeline**: From raw text to probabilistic training labels

### Core Concepts

**Labeling Functions (LFs)**: Simple functions that take an example and return a label or abstain. These encode domain expertise, heuristics, or weak signals.

**Label Model**: A generative model that estimates the true labels by learning the accuracy and correlation structure of the labeling functions.

**Weak Supervision**: The paradigm of using multiple noisy, programmatic supervision sources instead of manual labels.
```bash
labelforge run --config config.yaml
```
Complete automation from raw data to trained models with configurable workflows

**Analytics and Monitoring**
- Real-time labeling function performance analysis
## Installation

LabelForge requires Python 3.8+ and can be installed from PyPI or source.

### From PyPI (Recommended)

```bash
# Basic installation
pip install labelforge

# With web interface (recommended)
pip install labelforge[web]

# Full installation with all features
pip install labelforge[all]
```

### From Source (For Development)

```bash
git clone https://github.com/sonishsivarajkumar/LabelForge.git
cd LabelForge
pip install -e .
```

### Development Installation

For contributing or extending the framework:

```bash
git clone https://github.com/sonishsivarajkumar/LabelForge.git
cd LabelForge
pip install -e ".[dev]"
pre-commit install  # Optional: install git hooks
```

### Dependencies

- **Core**: numpy, pandas, scipy, scikit-learn
- **CLI**: click, rich
- **Web Interface**: streamlit, plotly, altair
- **Dev**: pytest, black, flake8, mypy, pre-commit

### Web Dependencies

For the interactive web interface:

```bash
pip install labelforge[web]
# or
pip install streamlit plotly altair streamlit-aggrid
```

## üåê Web Interface (NEW!)

LabelForge now includes a modern, interactive web interface perfect for researchers and practitioners who prefer visual tools:

```bash
# Launch the web interface
./start_web.sh
# or
streamlit run src/labelforge/web/app.py
```

**Access at:** http://localhost:8501

### Web Interface Features:
- üìÅ **Drag-and-drop data upload** (CSV, JSON, text files)
- ‚öôÔ∏è **Visual labeling function creation** (keyword, regex, custom code)
- ü§ñ **Interactive model training** with real-time feedback
- üìà **Performance visualization** and conflict analysis
- üìã **Results browsing** with filtering and export options
- üî¨ **Research-focused design** for systematic experimentation

## Quick Start

### Option 1: Web Interface (Recommended for Beginners)

```bash
# Install with web dependencies
pip install labelforge[web]

# Launch the interactive interface
./start_web.sh

# Open http://localhost:8501 in your browser
```

The web interface provides a complete guided experience:
1. Upload your data or use sample datasets
2. Create labeling functions visually
3. Train models with real-time feedback
4. Analyze results and export predictions

### Option 2: Python API

Here's a minimal example showing the core workflow:

```python
from labelforge import lf, LabelModel, apply_lfs, Example

# Create some example data
examples = [
    Example(text="Patient has type 2 diabetes"),
    Example(text="No diabetic symptoms observed"),
    Example(text="Blood glucose levels elevated"),
    Example(text="Regular checkup, no issues")
]

# Define labeling functions
@lf(name="diabetes_mention")
def has_diabetes_keyword(example):
    """Label examples mentioning diabetes directly."""
    return 1 if "diabetes" in example.text.lower() else 0

@lf(name="diabetes_indicators") 
def has_diabetes_indicators(example):
    """Label examples with diabetes-related terms."""
    indicators = ["glucose", "insulin", "diabetic"]
    text = example.text.lower()
    return 1 if any(term in text for term in indicators) else -1  # abstain if no match

# Apply labeling functions
lf_output = apply_lfs(examples)

# Train label model to combine LF outputs
label_model = LabelModel(cardinality=2)
label_model.fit(lf_output)

# Get probabilistic labels
probs = label_model.predict_proba(lf_output)
predictions = label_model.predict(lf_output)

print(f"Predictions: {predictions}")
print(f"Probabilities shape: {probs.shape}")
```

For more examples, see the [examples/](examples/) directory and [documentation](docs/).

## üé• Quick Demo

Try the web interface with sample data:

```bash
# Install and launch
pip install labelforge[web]
./start_web.sh

# In the web interface:
# 1. Go to Overview ‚Üí Click "üöÄ Load Sample Medical Dataset"
# 2. Navigate to "‚öôÔ∏è Labeling Functions" ‚Üí Create keyword-based functions
# 3. Go to "ü§ñ Label Model" ‚Üí Train with default settings
# 4. Explore "üìà Analysis" ‚Üí View performance and conflicts
# 5. Check "üìã Results" ‚Üí Browse predictions and export
```

## API Reference

### Core Classes

#### `@lf` decorator
```python
@lf(name="my_function", tags={"type": "keyword"}, abstain_label=-1)
def my_labeling_function(example):
    """Your labeling logic here."""
    return label  # or abstain_label
```

#### `LabelModel`
```python
# Generative model for learning from labeling functions
model = LabelModel(
    cardinality=2,        # Number of classes
    max_iter=100,         # EM iterations
    tol=1e-4,            # Convergence tolerance
    verbose=True
)
model.fit(lf_output)
probs = model.predict_proba(lf_output)
```

#### `apply_lfs`
```python
# Apply all registered LFs to examples
lf_output = apply_lfs(examples)

# Apply specific LFs
lf_output = apply_lfs(examples, lfs=[lf1, lf2])
```

### Command Line Interface

```bash
# View registered labeling functions
labelforge lf-list

# Analyze LF performance and conflicts  
labelforge lf-stats

# Test LFs on sample data
labelforge lf-test --dataset examples/data.json

# Run end-to-end pipeline
labelforge run --input data/ --output results/
```

### üåê Web Interface

LabelForge now includes a modern, interactive web interface built with Streamlit, designed specifically for researchers and practitioners who prefer visual tools.

```bash
# Launch the web interface
labelforge web

# Or use the direct command
streamlit run src/labelforge/web/app.py
```

**Key Features:**
- **Interactive Data Upload**: Drag-and-drop CSV, JSON, and text files
- **Visual LF Creation**: Build labeling functions with guided forms
- **Real-time Analysis**: Live performance metrics and conflict visualization
- **Export Results**: Download predictions in multiple formats
- **Research-Focused**: Designed for academic experimentation and systematic studies

Access the interface at `http://localhost:8501` after launching.

## Research & Citations

LabelForge implements concepts from several research papers in weak supervision:

1. **Snorkel**: Ratner et al. "Snorkel: Rapid Training Data Creation with Weak Supervision" (2017)
2. **Data Programming**: Ratner et al. "Data Programming: Creating Large Training Sets, Quickly" (2016)  
3. **Coral**: Hancock et al. "Training Classifiers with Natural Language Explanations" (2018)

### Using LabelForge in Research

If you use LabelForge in academic work, please consider citing:

```bibtex
@software{labelforge2025,
  title={LabelForge: Open-Source Framework for Programmatic Weak Supervision},
  author={Sonish Sivarajkumar},
  year={2025},
  url={https://github.com/sonishsivarajkumar/LabelForge},
  version={0.1.0},
  note={Available on PyPI: https://pypi.org/project/labelforge/}
}
```

### Related Work & Comparisons

- **Snorkel**: Original weak supervision framework (Stanford)
- **Wrench**: Benchmarking framework for weak supervision
- **cleanlab**: Data-centric AI and label quality
- **skweak**: Weak supervision for NLP (spaCy ecosystem)

## Examples

### Medical Text Classification

```python
from labelforge import lf, load_example_data

# Load medical dataset
examples = load_example_data("medical_texts")

@lf(name="diabetes_keywords")
def diabetes_mention(example):
    keywords = ["diabetes", "diabetic", "glucose", "insulin"]
    return 1 if any(k in example.text.lower() for k in keywords) else 0

@lf(name="diabetes_medications")
def diabetes_drugs(example):
    drugs = ["metformin", "insulin", "glipizide", "glyburide"]
    return 1 if any(d in example.text.lower() for d in drugs) else 0

# See examples/medical_example.py for complete implementation
```

### Sentiment Analysis

```python
@lf(name="positive_sentiment")
def sentiment_positive(example):
    positive_words = ["excellent", "amazing", "love", "perfect", "great"]
    return 1 if any(word in example.text.lower() for word in positive_words) else 0

@lf(name="negative_sentiment") 
def sentiment_negative(example):
    negative_words = ["terrible", "awful", "hate", "worst", "bad"]
    return 1 if any(word in example.text.lower() for word in negative_words) else 0
```

### Using External Models

```python
# Example: Using pre-trained models as labeling functions
@lf(name="external_classifier")
def external_model_lf(example):
    # Your external model prediction logic
    confidence = external_model.predict_proba(example.text)[0].max()
    return 1 if confidence > 0.8 else -1  # abstain if low confidence
```

More examples available in the [examples/](examples/) directory.

## Architecture & Implementation

### Core Components

**Labeling Functions (`lf.py`)**
- Function decorator and registry system
- Performance tracking and error handling
- Support for abstention and metadata

**Label Model (`label_model.py`)**
- Generative model P(L, Y) implementation
- EM algorithm for parameter estimation
- Handles correlations and class imbalance

**Data Structures (`types.py`)**
- `Example`: Container for text and metadata
- `LFOutput`: Vote matrix with analysis methods
- Type hints and validation

### Algorithm Details

The label model implements a generative approach:

1. **Generative Model**: P(L, Y) = P(Y) ‚àè P(L_i | Y)
2. **EM Algorithm**: Alternates between:
   - E-step: Compute P(Y | L) using current parameters
   - M-step: Update parameters Œ± (accuracies) and œÄ (priors)
3. **Parameter Learning**: 
   - Accuracy: Œ±_i = P(L_i = Y | Y)
   - Priors: œÄ_c = P(Y = c)

## Performance & Benchmarks

### Computational Complexity

- **LF Application**: O(n √ó m) where n=examples, m=functions
- **EM Training**: O(n √ó m √ó c √ó k) where c=classes, k=iterations
- **Memory**: O(n √ó m) for vote matrix storage

### Typical Performance

| Dataset Size | Functions | Training Time | Memory Usage |
|--------------|-----------|---------------|--------------|
| 1K examples  | 5 LFs     | < 1s          | ~10MB        |
| 10K examples | 10 LFs    | ~5s           | ~50MB        |
| 100K examples| 20 LFs    | ~30s          | ~200MB       |

Performance scales linearly with dataset size and number of functions.

---

## Roadmap

### Current Status (v0.1.0) ‚úÖ
- ‚úÖ Core labeling function framework
- ‚úÖ Probabilistic label model with EM algorithm  
- ‚úÖ Command-line interface
- ‚úÖ Basic analytics and visualization
- ‚úÖ Example datasets and documentation
- ‚úÖ **Web-based user interface with interactive features**

### Version 1.0 (Target: Q3 2025) üöß
- ‚úÖ Web-based user interface
- üöß Advanced model diagnostics
- üöß Integration with popular ML frameworks
- üöß Comprehensive documentation and tutorials
- üöß Performance optimizations

### Version 1.1 (Target: Q4 2025)
- üìã Discriminative model training pipeline
- üìã Advanced conflict resolution algorithms
- üìã Real-time monitoring dashboard
- üìã Plugin system for extensibility

### Version 2.0 (Target: Q1 2026)
- üìã LLM-enhanced labeling function generation
- üìã Active learning integration
- üìã Multi-modal data support (images, audio)
- üìã Distributed computing support
- üìã Enterprise features and support

### Future Releases
- üìã AutoML integration
- üìã Real-time streaming data support
- üìã Advanced visualization and explainability
- üìã Cloud deployment and scaling

---

## Contributing

LabelForge is an open-source project that welcomes contributions from researchers, students, and practitioners. We aim to build a collaborative tool for the research community.

### Ways to Contribute

- **Research**: Implement new algorithms, improve existing methods
- **Documentation**: Tutorials, examples, use case studies
- **Bug Reports**: Help us identify and fix issues
- **Feature Requests**: Suggest new functionality for the research community
- **Examples**: Contribute domain-specific examples and datasets

### Development Setup

```bash
# Clone the repository
git clone https://github.com/sonishsivarajkumar/LabelForge.git
cd LabelForge

# Create development environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -e ".[dev]"

# Install pre-commit hooks (optional)
pre-commit install

# Run tests
pytest tests/ -v

# Run code quality checks
black src/ tests/
flake8 src/ tests/
mypy src/
```

### Contribution Process

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/new-algorithm`)
3. **Add tests** for your changes
4. **Ensure** all tests pass (`pytest tests/`)
5. **Submit** a pull request with clear description

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

## Community

### Getting Help

- **üìñ Documentation**: Browse the [docs/](docs/) directory
- **üêõ Issues**: [Report bugs](https://github.com/sonishsivarajkumar/LabelForge/issues) and request features
- **üí¨ Discussions**: Share use cases and ask questions
- **üìß Contact**: Reach out for research collaborations

### Research Community

LabelForge is designed for:
- **Academic researchers** studying weak supervision
- **NLP practitioners** needing labeled data
- **Data scientists** working with limited labeled datasets
- **Students** learning about machine learning and data programming

### Open Source Ecosystem

We aim to be a good citizen in the open-source ML ecosystem:
- **Interoperability**: Works with scikit-learn, pandas, numpy
- **Standards**: Follows Python packaging and typing standards  
- **Testing**: Comprehensive test suite with CI/CD
- **Documentation**: Clear docs for users and contributors

## License

LabelForge is released under the **Apache 2.0 License**, enabling both research and commercial use.

```
Copyright 2025 LabelForge Contributors

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0
```

See [LICENSE](LICENSE) for the full license text.

## Acknowledgments

**Research Foundation**  
LabelForge builds upon foundational research in weak supervision:
- Ratner et al. "Snorkel: Rapid Training Data Creation with Weak Supervision"
- Bach et al. "Learning the Structure of Generative Models without Labeled Data"
- Varma & R√© "Snuba: Automating Weak Supervision to Label Training Data"

**Inspiration**  
- **Snorkel**: Original weak supervision framework
- **Wrench**: Comprehensive benchmarking platform  
- **cleanlab**: Data-centric AI principles

**Contributors**  
Thanks to all contributors who help build and improve LabelForge. See [CONTRIBUTORS.md](CONTRIBUTORS.md) for the full list.

---
